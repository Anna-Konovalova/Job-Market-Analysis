{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://uk.indeed.com/jobs?q=software+developer&l=United+Kingdom&start=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(page):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36'}\n",
    "    url = f'https://uk.indeed.com/jobs?q=software+developer&l=United+Kingdom&start={page}'\n",
    "    r = requests.get(url, headers)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(soup):\n",
    "    divs = soup.find_all('div', class_ = 'jobsearch-SerpJobCard')\n",
    "    for item in divs:\n",
    "        title = item.find('a').text.strip()\n",
    "        company = item.find('span', class_ = 'company').text.strip()\n",
    "        try:\n",
    "            salary = item.find('span', class_ = 'salaryText').text.strip()\n",
    "        except:\n",
    "            salary = ''\n",
    "        summary = item.find('div', class_ = 'summary').text.strip().replace('\\n', '')\n",
    "        location = item.find('div', class_ = 'recJobLoc').get('data-rc-loc')\n",
    "        post_date = item.find('span', class_ = 'date').text.strip()\n",
    "        today = datetime.today().strftime('%Y-%m-%d')\n",
    "        job_url = 'https://indeed.com' + item.find('a').get('href')\n",
    "        \n",
    "        \n",
    "        job = {\n",
    "            'title' : title,\n",
    "            'company' : company,\n",
    "            'salary' : salary,\n",
    "            'summary' : summary,\n",
    "            'location' : location,\n",
    "            'post_date' : post_date,\n",
    "            'today' : today,\n",
    "            'job_url' : job_url\n",
    "        }\n",
    "        joblist.append(job)\n",
    "    return\n",
    "\n",
    "joblist = []\n",
    "\n",
    "for i in range(0, 991, 10):\n",
    "    c = extract(0)        \n",
    "    transform(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(joblist)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.to_csv('jobs_scraped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
